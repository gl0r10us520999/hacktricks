# free

{% hint style="success" %}
AWS Hacking'i Ã¶ÄŸrenin ve pratik yapÄ±n:<img src="/.gitbook/assets/arte.png" alt="" data-size="line">[**HackTricks Training AWS Red Team Expert (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/arte.png" alt="" data-size="line">\
GCP Hacking'i Ã¶ÄŸrenin ve pratik yapÄ±n: <img src="/.gitbook/assets/grte.png" alt="" data-size="line">[**HackTricks Training GCP Red Team Expert (GRTE)**<img src="/.gitbook/assets/grte.png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>HackTricks'i Destekleyin</summary>

* [**abonelik planlarÄ±nÄ±**](https://github.com/sponsors/carlospolop) kontrol edin!
* **Bize katÄ±lÄ±n** ğŸ’¬ [**Discord grubuna**](https://discord.gg/hRep4RUj7f) veya [**telegram grubuna**](https://t.me/peass) veya **bizi** **Twitter'da** ğŸ¦ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)** takip edin.**
* **Hacking ipuÃ§larÄ±nÄ± paylaÅŸmak iÃ§in** [**HackTricks**](https://github.com/carlospolop/hacktricks) ve [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github reposuna PR gÃ¶nderin.

</details>
{% endhint %}

## Free Order Summary <a href="#libc_free" id="libc_free"></a>

(Bu Ã¶zet iÃ§inde kontroller aÃ§Ä±klanmamÄ±ÅŸtÄ±r ve bazÄ± durumlar kÄ±salÄ±k iÃ§in atlanmÄ±ÅŸtÄ±r)

1. EÄŸer adres null ise hiÃ§bir ÅŸey yapmayÄ±n
2. EÄŸer parÃ§a mmaped ise, mummap yapÄ±n ve bitirin
3. `_int_free` Ã§aÄŸÄ±rÄ±n:
   1. MÃ¼mkÃ¼nse, parÃ§ayÄ± tcache'e ekleyin
   2. MÃ¼mkÃ¼nse, parÃ§ayÄ± fast bin'e ekleyin
   3. Gerekirse parÃ§ayÄ± birleÅŸtirmek iÃ§in `_int_free_merge_chunk` Ã§aÄŸÄ±rÄ±n ve sÄ±ralanmamÄ±ÅŸ listeye ekleyin

## \_\_libc\_free <a href="#libc_free" id="libc_free"></a>

`Free` `__libc_free` Ã§aÄŸÄ±rÄ±r.

* GeÃ§ilen adres Null (0) ise hiÃ§bir ÅŸey yapmayÄ±n.
* Pointer etiketini kontrol edin
* EÄŸer parÃ§a `mmaped` ise, `mummap` yapÄ±n ve hepsi bu
* DeÄŸilse, rengi ekleyin ve Ã¼zerinde `_int_free` Ã§aÄŸÄ±rÄ±n

<details>

<summary>__lib_free kodu</summary>
```c
void
__libc_free (void *mem)
{
mstate ar_ptr;
mchunkptr p;                          /* chunk corresponding to mem */

if (mem == 0)                              /* free(0) has no effect */
return;

/* Quickly check that the freed pointer matches the tag for the memory.
This gives a useful double-free detection.  */
if (__glibc_unlikely (mtag_enabled))
*(volatile char *)mem;

int err = errno;

p = mem2chunk (mem);

if (chunk_is_mmapped (p))                       /* release mmapped memory. */
{
/* See if the dynamic brk/mmap threshold needs adjusting.
Dumped fake mmapped chunks do not affect the threshold.  */
if (!mp_.no_dyn_threshold
&& chunksize_nomask (p) > mp_.mmap_threshold
&& chunksize_nomask (p) <= DEFAULT_MMAP_THRESHOLD_MAX)
{
mp_.mmap_threshold = chunksize (p);
mp_.trim_threshold = 2 * mp_.mmap_threshold;
LIBC_PROBE (memory_mallopt_free_dyn_thresholds, 2,
mp_.mmap_threshold, mp_.trim_threshold);
}
munmap_chunk (p);
}
else
{
MAYBE_INIT_TCACHE ();

/* Mark the chunk as belonging to the library again.  */
(void)tag_region (chunk2mem (p), memsize (p));

ar_ptr = arena_for_chunk (p);
_int_free (ar_ptr, p, 0);
}

__set_errno (err);
}
libc_hidden_def (__libc_free)
```
</details>

## \_int\_free <a href="#int_free" id="int_free"></a>

### \_int\_free baÅŸlangÄ±cÄ± <a href="#int_free" id="int_free"></a>

BazÄ± kontrollerle baÅŸlar, bunlar ÅŸunlarÄ± garanti eder:

* **iÅŸaretÃ§i** **hizalanmÄ±ÅŸ**tÄ±r, aksi takdirde hata `free(): invalid pointer` tetiklenir
* **boyut** minimumdan daha az deÄŸildir ve **boyut** da **hizalanmÄ±ÅŸ**tÄ±r, aksi takdirde hata: `free(): invalid size`

<details>

<summary>_int_free baÅŸlangÄ±cÄ±</summary>
```c
// From https://github.com/bminor/glibc/blob/f942a732d37a96217ef828116ebe64a644db18d7/malloc/malloc.c#L4493C1-L4513C28

#define aligned_OK(m) (((unsigned long) (m) &MALLOC_ALIGN_MASK) == 0)

static void
_int_free (mstate av, mchunkptr p, int have_lock)
{
INTERNAL_SIZE_T size;        /* its size */
mfastbinptr *fb;             /* associated fastbin */

size = chunksize (p);

/* Little security check which won't hurt performance: the
allocator never wraps around at the end of the address space.
Therefore we can exclude some size values which might appear
here by accident or by "design" from some intruder.  */
if (__builtin_expect ((uintptr_t) p > (uintptr_t) -size, 0)
|| __builtin_expect (misaligned_chunk (p), 0))
malloc_printerr ("free(): invalid pointer");
/* We know that each chunk is at least MINSIZE bytes in size or a
multiple of MALLOC_ALIGNMENT.  */
if (__glibc_unlikely (size < MINSIZE || !aligned_OK (size)))
malloc_printerr ("free(): invalid size");

check_inuse_chunk(av, p);
```
</details>

### \_int\_free tcache <a href="#int_free" id="int_free"></a>

Ã–ncelikle bu parÃ§ayÄ± ilgili tcache'de tahsis etmeye Ã§alÄ±ÅŸacaktÄ±r. Ancak, bazÄ± kontroller Ã¶nceden yapÄ±lÄ±r. Serbest bÄ±rakÄ±lan parÃ§anÄ±n aynÄ± indeksindeki tcache'deki tÃ¼m parÃ§alarÄ± dÃ¶ngÃ¼ye alÄ±r ve:

* EÄŸer `mp_.tcache_count`'dan daha fazla giriÅŸ varsa: `free(): tcache'de Ã§ok fazla parÃ§a tespit edildi`
* EÄŸer giriÅŸ hizalanmamÄ±ÅŸsa: free(): `tcache 2'de hizalanmamÄ±ÅŸ parÃ§a tespit edildi`
* EÄŸer serbest bÄ±rakÄ±lan parÃ§a zaten serbest bÄ±rakÄ±lmÄ±ÅŸsa ve tcache'de parÃ§a olarak mevcutsa: `free(): tcache 2'de Ã§ift serbest bÄ±rakma tespit edildi`

Her ÅŸey yolunda giderse, parÃ§a tcache'e eklenir ve fonksiyon geri dÃ¶ner.

<details>

<summary>_int_free tcache</summary>
```c
// From https://github.com/bminor/glibc/blob/f942a732d37a96217ef828116ebe64a644db18d7/malloc/malloc.c#L4515C1-L4554C7
#if USE_TCACHE
{
size_t tc_idx = csize2tidx (size);
if (tcache != NULL && tc_idx < mp_.tcache_bins)
{
/* Check to see if it's already in the tcache.  */
tcache_entry *e = (tcache_entry *) chunk2mem (p);

/* This test succeeds on double free.  However, we don't 100%
trust it (it also matches random payload data at a 1 in
2^<size_t> chance), so verify it's not an unlikely
coincidence before aborting.  */
if (__glibc_unlikely (e->key == tcache_key))
{
tcache_entry *tmp;
size_t cnt = 0;
LIBC_PROBE (memory_tcache_double_free, 2, e, tc_idx);
for (tmp = tcache->entries[tc_idx];
tmp;
tmp = REVEAL_PTR (tmp->next), ++cnt)
{
if (cnt >= mp_.tcache_count)
malloc_printerr ("free(): too many chunks detected in tcache");
if (__glibc_unlikely (!aligned_OK (tmp)))
malloc_printerr ("free(): unaligned chunk detected in tcache 2");
if (tmp == e)
malloc_printerr ("free(): double free detected in tcache 2");
/* If we get here, it was a coincidence.  We've wasted a
few cycles, but don't abort.  */
}
}

if (tcache->counts[tc_idx] < mp_.tcache_count)
{
tcache_put (p, tc_idx);
return;
}
}
}
#endif
```
</details>

### \_int\_free fast bin <a href="#int_free" id="int_free"></a>

Ã–ncelikle boyutun fast bin iÃ§in uygun olup olmadÄ±ÄŸÄ±nÄ± kontrol edin ve onu Ã¼st chunk'a yakÄ±n bir ÅŸekilde ayarlamanÄ±n mÃ¼mkÃ¼n olup olmadÄ±ÄŸÄ±nÄ± kontrol edin.

ArdÄ±ndan, bazÄ± kontroller yaparak serbest bÄ±rakÄ±lan chunk'Ä± fast bin'in en Ã¼stÃ¼ne ekleyin:

* EÄŸer chunk'Ä±n boyutu geÃ§ersizse (Ã§ok bÃ¼yÃ¼k veya kÃ¼Ã§Ã¼k) tetikleyin: `free(): invalid next size (fast)`
* EÄŸer eklenen chunk zaten fast bin'in en Ã¼stÃ¼ndeyse: `double free or corruption (fasttop)`
* EÄŸer en Ã¼stteki chunk'Ä±n boyutu, eklediÄŸimiz chunk'Ä±n boyutundan farklÄ±ysa: `invalid fastbin entry (free)`

<details>

<summary>_int_free Fast Bin</summary>
```c
// From https://github.com/bminor/glibc/blob/f942a732d37a96217ef828116ebe64a644db18d7/malloc/malloc.c#L4556C2-L4631C4

/*
If eligible, place chunk on a fastbin so it can be found
and used quickly in malloc.
*/

if ((unsigned long)(size) <= (unsigned long)(get_max_fast ())

#if TRIM_FASTBINS
/*
If TRIM_FASTBINS set, don't place chunks
bordering top into fastbins
*/
&& (chunk_at_offset(p, size) != av->top)
#endif
) {

if (__builtin_expect (chunksize_nomask (chunk_at_offset (p, size))
<= CHUNK_HDR_SZ, 0)
|| __builtin_expect (chunksize (chunk_at_offset (p, size))
>= av->system_mem, 0))
{
bool fail = true;
/* We might not have a lock at this point and concurrent modifications
of system_mem might result in a false positive.  Redo the test after
getting the lock.  */
if (!have_lock)
{
__libc_lock_lock (av->mutex);
fail = (chunksize_nomask (chunk_at_offset (p, size)) <= CHUNK_HDR_SZ
|| chunksize (chunk_at_offset (p, size)) >= av->system_mem);
__libc_lock_unlock (av->mutex);
}

if (fail)
malloc_printerr ("free(): invalid next size (fast)");
}

free_perturb (chunk2mem(p), size - CHUNK_HDR_SZ);

atomic_store_relaxed (&av->have_fastchunks, true);
unsigned int idx = fastbin_index(size);
fb = &fastbin (av, idx);

/* Atomically link P to its fastbin: P->FD = *FB; *FB = P;  */
mchunkptr old = *fb, old2;

if (SINGLE_THREAD_P)
{
/* Check that the top of the bin is not the record we are going to
add (i.e., double free).  */
if (__builtin_expect (old == p, 0))
malloc_printerr ("double free or corruption (fasttop)");
p->fd = PROTECT_PTR (&p->fd, old);
*fb = p;
}
else
do
{
/* Check that the top of the bin is not the record we are going to
add (i.e., double free).  */
if (__builtin_expect (old == p, 0))
malloc_printerr ("double free or corruption (fasttop)");
old2 = old;
p->fd = PROTECT_PTR (&p->fd, old);
}
while ((old = catomic_compare_and_exchange_val_rel (fb, p, old2))
!= old2);

/* Check that size of fastbin chunk at the top is the same as
size of the chunk that we are adding.  We can dereference OLD
only if we have the lock, otherwise it might have already been
allocated again.  */
if (have_lock && old != NULL
&& __builtin_expect (fastbin_index (chunksize (old)) != idx, 0))
malloc_printerr ("invalid fastbin entry (free)");
}
```
</details>

### \_int\_free finale <a href="#int_free" id="int_free"></a>

EÄŸer parÃ§a henÃ¼z herhangi bir kutuda tahsis edilmemiÅŸse, `_int_free_merge_chunk` Ã§aÄŸrÄ±sÄ±nÄ± yapÄ±n.

<details>

<summary>_int_free finale</summary>
```c
/*
Consolidate other non-mmapped chunks as they arrive.
*/

else if (!chunk_is_mmapped(p)) {

/* If we're single-threaded, don't lock the arena.  */
if (SINGLE_THREAD_P)
have_lock = true;

if (!have_lock)
__libc_lock_lock (av->mutex);

_int_free_merge_chunk (av, p, size);

if (!have_lock)
__libc_lock_unlock (av->mutex);
}
/*
If the chunk was allocated via mmap, release via munmap().
*/

else {
munmap_chunk (p);
}
}
```
</details>

## \_int\_free\_merge\_chunk

Bu fonksiyon, P parÃ§asÄ±nÄ± SIZE bayt ile komÅŸularÄ±yla birleÅŸtirmeye Ã§alÄ±ÅŸacaktÄ±r. Ortaya Ã§Ä±kan parÃ§ayÄ± sÄ±ralanmamÄ±ÅŸ kutu listesine koyar.

BazÄ± kontroller yapÄ±lÄ±r:

* EÄŸer parÃ§a Ã¼st parÃ§a ise: `double free or corruption (top)`
* EÄŸer bir sonraki parÃ§a arenanÄ±n sÄ±nÄ±rlarÄ±nÄ±n dÄ±ÅŸÄ±ndaysa: `double free or corruption (out)`
* EÄŸer parÃ§a kullanÄ±lmÄ±yor olarak iÅŸaretlenmemiÅŸse (bir sonraki parÃ§anÄ±n `prev_inuse`'unda): `double free or corruption (!prev)`
* EÄŸer bir sonraki parÃ§anÄ±n boyutu Ã§ok kÃ¼Ã§Ã¼k veya Ã§ok bÃ¼yÃ¼kse: `free(): invalid next size (normal)`
* EÄŸer bir Ã¶nceki parÃ§a kullanÄ±lmÄ±yorsa, birleÅŸtirmeye Ã§alÄ±ÅŸacaktÄ±r. Ancak, eÄŸer prev\_size, bir Ã¶nceki parÃ§adaki belirtilen boyuttan farklÄ±ysa: `corrupted size vs. prev_size while consolidating`

<details>

<summary>_int_free_merge_chunk code</summary>
```c
// From https://github.com/bminor/glibc/blob/f942a732d37a96217ef828116ebe64a644db18d7/malloc/malloc.c#L4660C1-L4702C2

/* Try to merge chunk P of SIZE bytes with its neighbors.  Put the
resulting chunk on the appropriate bin list.  P must not be on a
bin list yet, and it can be in use.  */
static void
_int_free_merge_chunk (mstate av, mchunkptr p, INTERNAL_SIZE_T size)
{
mchunkptr nextchunk = chunk_at_offset(p, size);

/* Lightweight tests: check whether the block is already the
top block.  */
if (__glibc_unlikely (p == av->top))
malloc_printerr ("double free or corruption (top)");
/* Or whether the next chunk is beyond the boundaries of the arena.  */
if (__builtin_expect (contiguous (av)
&& (char *) nextchunk
>= ((char *) av->top + chunksize(av->top)), 0))
malloc_printerr ("double free or corruption (out)");
/* Or whether the block is actually not marked used.  */
if (__glibc_unlikely (!prev_inuse(nextchunk)))
malloc_printerr ("double free or corruption (!prev)");

INTERNAL_SIZE_T nextsize = chunksize(nextchunk);
if (__builtin_expect (chunksize_nomask (nextchunk) <= CHUNK_HDR_SZ, 0)
|| __builtin_expect (nextsize >= av->system_mem, 0))
malloc_printerr ("free(): invalid next size (normal)");

free_perturb (chunk2mem(p), size - CHUNK_HDR_SZ);

/* Consolidate backward.  */
if (!prev_inuse(p))
{
INTERNAL_SIZE_T prevsize = prev_size (p);
size += prevsize;
p = chunk_at_offset(p, -((long) prevsize));
if (__glibc_unlikely (chunksize(p) != prevsize))
malloc_printerr ("corrupted size vs. prev_size while consolidating");
unlink_chunk (av, p);
}

/* Write the chunk header, maybe after merging with the following chunk.  */
size = _int_free_create_chunk (av, p, size, nextchunk, nextsize);
_int_free_maybe_consolidate (av, size);
}
```
</details>

{% hint style="success" %}
AWS Hacking'i Ã¶ÄŸrenin ve pratik yapÄ±n:<img src="/.gitbook/assets/arte.png" alt="" data-size="line">[**HackTricks EÄŸitim AWS KÄ±rmÄ±zÄ± TakÄ±m UzmanÄ± (ARTE)**](https://training.hacktricks.xyz/courses/arte)<img src="/.gitbook/assets/arte.png" alt="" data-size="line">\
GCP Hacking'i Ã¶ÄŸrenin ve pratik yapÄ±n: <img src="/.gitbook/assets/grte.png" alt="" data-size="line">[**HackTricks EÄŸitim GCP KÄ±rmÄ±zÄ± TakÄ±m UzmanÄ± (GRTE)**<img src="/.gitbook/assets/grte.png" alt="" data-size="line">](https://training.hacktricks.xyz/courses/grte)

<details>

<summary>HackTricks'i Destekleyin</summary>

* [**abonelik planlarÄ±nÄ±**](https://github.com/sponsors/carlospolop) kontrol edin!
* **ğŸ’¬ [**Discord grubuna**](https://discord.gg/hRep4RUj7f) veya [**telegram grubuna**](https://t.me/peass) katÄ±lÄ±n ya da **Twitter'da** ğŸ¦ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**'i takip edin.**
* **Hacking ipuÃ§larÄ±nÄ± paylaÅŸmak iÃ§in** [**HackTricks**](https://github.com/carlospolop/hacktricks) ve [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github reposuna PR gÃ¶nderin.

</details>
{% endhint %}
